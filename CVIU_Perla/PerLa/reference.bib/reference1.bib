
@article{frey_clustering_2007,
	title = {Clustering by Passing Messages Between Data Points},
	volume = {315},
	url = {http://www.sciencemag.org/content/315/5814/972.abstract},
	doi = {10.1126/science.1136800},
	abstract = {Clustering data by identifying a subset of representative examples is important for processing sensory signals and detecting patterns in data. Such “exemplars” can be found by randomly choosing an initial subset of data points and then iteratively refining it, but this works well only if that initial choice is close to a good solution. We devised a method called “affinity propagation,” which takes as input measures of similarity between pairs of data points. Real-valued messages are exchanged between data points until a high-quality set of exemplars and corresponding clusters gradually emerges. We used affinity propagation to cluster images of faces, detect genes in microarray data, identify representative sentences in this manuscript, and identify cities that are efficiently accessed by airline travel. Affinity propagation found clusters with much lower error than other methods, and it did so in less than one-hundredth the amount of time.},
	number = {5814},
	journal = {Science},
	author = {Frey, Brendan J. and Dueck, Delbert},
	month = feb,
	year = {2007},
	pages = {972 --976},
	file = {Snapshot:files/11/972.html:text/html}
},

@article{zivkovic_recursive_2004,
	title = {Recursive unsupervised learning of finite mixture models},
	volume = {26},
	issn = {0162-8828},
	doi = {10.1109/TPAMI.2004.1273970},
	abstract = {There are two open problems when finite mixture densities are used to model multivariate data: the selection of the number of components and the initialization. In this paper, we propose an online (recursive) algorithm that estimates the parameters of the mixture and that simultaneously selects the number of components. The new algorithm starts with a large number of randomly initialized components. A prior is used as a bias for maximally structured models. A stochastic approximation recursive learning algorithm is proposed to search for the maximum a posteriori {(MAP)} solution and to discard the irrelevant components.},
	number = {5},
	journal = {{IEEE} Transactions on Pattern Analysis and Machine Intelligence},
	author = {Zivkovic, Z. and van der Heijden, F.},
	month = may,
	year = {2004},
	keywords = {Algorithms, Approximation algorithms, Artificial Intelligence, Cluster Analysis, Computer Graphics, Computer Simulation, Computer Society, Entropy, Equations, finite mixture densities, finite mixture models, Information Storage and Retrieval, Iterative algorithms, Likelihood Functions, maximum a posteriori algorithm, Maximum likelihood estimation, Models, Biological, Models, Statistical, multivariate data modelling, Numerical Analysis, {Computer-Assisted}, online algorithm, Parameter estimation, Pattern Recognition, Automated, Recursive estimation, recursive unsupervised learning, Reproducibility of Results, Sensitivity and Specificity, stochastic approximation recursive learning algorithm, Stochastic Processes, Unsupervised learning, {User-Computer} Interface},
	pages = {651--656},
	file = {IEEE Xplore Full Text PDF:files/13/Zivkovic and van der Heijden - 2004 - Recursive unsupervised learning of finite mixture .pdf:application/pdf}
},

@article{goldberger_unsupervised_2006,
	title = {Unsupervised image-set clustering using an information theoretic framework},
	volume = {15},
	issn = {1057-7149},
	doi = {10.1109/TIP.2005.860593},
	abstract = {In this paper, we combine discrete and continuous image models with information-theoretic-based criteria for unsupervised hierarchical image-set clustering. The continuous image modeling is based on mixture of Gaussian densities. The unsupervised image-set clustering is based on a generalized version of a recently introduced information-theoretic principle, the information bottleneck principle. Images are clustered such that the mutual information between the clusters and the image content is maximally preserved. Experimental results demonstrate the performance of the proposed framework for image clustering on a large image set. Information theoretic tools are used to evaluate cluster quality. Particular emphasis is placed on the application of the clustering for efficient image search and retrieval.},
	number = {2},
	journal = {{IEEE} Transactions on Image Processing},
	author = {Goldberger, J. and Gordon, S. and Greenspan, H.},
	month = feb,
	year = {2006},
	keywords = {Algorithms, Artificial Intelligence, Biomedical engineering, Biomedical measurements, Cluster Analysis, content-based retrieval, continuous image model, Data analysis, Databases, Factual, discrete image model, Gaussian densities, Gaussian processes, Hierarchical database analysis, image clustering, image content based retrieval, image database management, Image databases, Image Enhancement, Image Interpretation, {Computer-Assisted}, image modeling, image representation, Image retrieval, information bottleneck {(IB)}, Information Storage and Retrieval, information theoretic framework, Information Theory, Jacobian matrices, Kullback\&\#8211, Leibler divergence, mixture of Gaussians, Mutual information, Navigation, pattern clustering, Pattern Recognition, Automated, retrieval, Spatial databases, Transaction databases, unsupervised image set clustering, visual databases},
	pages = {449--458},
	file = {IEEE Xplore Full Text PDF:files/4/Goldberger et al. - 2006 - Unsupervised image-set clustering using an informa.pdf:application/pdf}
}